\chapter{Methods}
\label{chap:methods}

All code used for this thesis can be found on \url{https://github.com/wwelvaer/thesis/tree/main/MassSpecGym}

\section{Model Training}
\label{sec:training}

All models trained for this Thesis follow the de novo model architecture from MassSpecGym~\cite{bushuiev2024massspecgym} closely.
Most of the model architecture code was heavily inspired by MassSpecGym's source code.
It uses the pytorch transformer implementation along with a linear layer before and after the transformer to achieve the requested input and output dimensions.
The training algorithm follows the original transformer implementation from \textcite{vaswani2017attention}.
The result is a model that predicts the probability distribution of the next token given the peaks of a \ac{MS/MS} spectrum along with an already generated context sequence of tokens.




\section{Samplers}
\label{sec:samplers}

\section{Augmentation}
\label{sec:augmentation}

\section{Molecular representations}
\label{sec:representations}
